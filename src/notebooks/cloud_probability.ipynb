{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=HWEd-em1BQTAmayY4SqfVs35K-PBRIls1069FxTXPRI&tc=Sfla0q41T9vJoZTQ30lab5v3vJbJF3Tclb50fO1qfFo&cc=_wCKBQ65zyW-nyBzP44QJ3STZhp8nDGwCqjqqhno3_Y>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=HWEd-em1BQTAmayY4SqfVs35K-PBRIls1069FxTXPRI&tc=Sfla0q41T9vJoZTQ30lab5v3vJbJF3Tclb50fO1qfFo&cc=_wCKBQ65zyW-nyBzP44QJ3STZhp8nDGwCqjqqhno3_Y</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "from datetime import datetime\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_point_df = pd.read_csv('data/10k_random.csv')\n",
    "coordinates = random_point_df[['lon', 'lat']].values.tolist()\n",
    "\n",
    "\n",
    "START_DATE = '2022-01-01'\n",
    "END_DATE = '2023-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "\n",
    "# filter according to time interval\n",
    "filtered_dataset = dataset.filterDate(ee.Date(START_DATE), ee.Date(END_DATE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "json_data = {}\n",
    "\n",
    "for i, coord in enumerate(coordinates):\n",
    "    print(\"Number of point: \", i)\n",
    "    lon, lat = coord\n",
    "    point = ee.Geometry.Point(coord)\n",
    "\n",
    "    # Her koordinat için processed_dates'i ve prob_data'yı sıfırla\n",
    "    processed_dates = set()\n",
    "    prob_data = {}\n",
    "\n",
    "    # filter\n",
    "    filtered_dataset_ = filtered_dataset.filterBounds(point)\n",
    "\n",
    "    for image in filtered_dataset_.toList(filtered_dataset_.size()).getInfo():\n",
    "        image_date = datetime.utcfromtimestamp(image['properties']['system:time_start'] / 1000.0).strftime('%Y-%m-%d')\n",
    "        print(f\"Processing image for date: {image_date}\")\n",
    "\n",
    "        # Check if the date has been processed already, if so, skip to the next image\n",
    "        if image_date in processed_dates:\n",
    "            print(f\"Skipping image for date {image_date} as it's already processed.\")\n",
    "            continue\n",
    "\n",
    "        selected_image = ee.Image(image['id'])\n",
    "        # ... (Diğer işlemleriniz buraya gelecek, örneğin bulut olasılığı hesaplama)\n",
    "\n",
    "        cloud_image = selected_image.select(['probability'])          \n",
    "        # Use reduceRegion to get all values, then extract the specific band value\n",
    "        cloud_dict = cloud_image.reduceRegion(reducer=ee.Reducer.mean(), geometry=point, scale=10).getInfo()\n",
    "        cloud_prob = cloud_dict.get('probability')\n",
    "\n",
    "        # Eğer bulut olasılığı None ise, veriyi eklemeyin\n",
    "        if cloud_prob is not None:\n",
    "            print(\"Cloud Prob: \", cloud_prob)\n",
    "            prob_data[image_date] = cloud_prob\n",
    "\n",
    "        # Add the processed date to the set\n",
    "        processed_dates.add(image_date)\n",
    "\n",
    "    # Koordinat ID'sini ve ilgili verileri JSON yapısına ekle\n",
    "    coord_id = f'{i}'  # Koordinat için benzersiz bir ID oluştur\n",
    "    json_data[coord_id] = {\n",
    "        'lon': lon,\n",
    "        'lat': lat,\n",
    "        'probabilities': prob_data\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/cloud_probabilities.json'\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
