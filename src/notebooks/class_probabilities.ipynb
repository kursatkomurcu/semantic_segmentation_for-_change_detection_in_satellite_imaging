{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras import applications, optimizers\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout\n",
    "\n",
    "import ee\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_inception_resnetv2_unet(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \"\"\" Pre-trained InceptionResNetV2 Model \"\"\"\n",
    "    encoder = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = encoder.get_layer(\"input_1\").output           ## (512 x 512)\n",
    "\n",
    "    s2 = encoder.get_layer(\"activation\").output        ## (255 x 255)\n",
    "    s2 = ZeroPadding2D(( (1, 0), (1, 0) ))(s2)         ## (256 x 256)\n",
    "\n",
    "    s3 = encoder.get_layer(\"activation_3\").output      ## (126 x 126)\n",
    "    s3 = ZeroPadding2D((1, 1))(s3)                     ## (128 x 128)\n",
    "\n",
    "    s4 = encoder.get_layer(\"activation_74\").output      ## (61 x 61)\n",
    "    s4 = ZeroPadding2D(( (2, 1),(2, 1) ))(s4)           ## (64 x 64)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = encoder.get_layer(\"activation_161\").output     ## (30 x 30)\n",
    "    b1 = ZeroPadding2D((1, 1))(b1)                      ## (32 x 32)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
    "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
    "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
    "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
    "    \n",
    "    \"\"\" Output \"\"\"\n",
    "    dropout = Dropout(0.3)(d4)\n",
    "    outputs = Conv2D(6, 1, padding=\"same\", activation=\"softmax\")(dropout)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"InceptionResNetV2-UNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n",
    "\n",
    "model = build_inception_resnetv2_unet(input_shape = (512, 512, 3))\n",
    "model.compile(optimizer=Adam(lr = 0.0001), loss='categorical_crossentropy', metrics=[dice_coef, \"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"InceptionResNetV2-UNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_point_df = pd.read_csv('10k_random.csv')\n",
    "coordinates = random_point_df[['lon', 'lat']].values.tolist()\n",
    "coordinates = coordinates[:100]\n",
    "# point = ee.Geometry.Point(coordinate)\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2023-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ee.ImageCollection('COPERNICUS/S2')\n",
    "\n",
    "# filter according to time interval\n",
    "filtered_dataset = dataset.filterDate(ee.Date(start_date), ee.Date(end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "\n",
    "data = {}\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "    print(\"Number of point: \", i)\n",
    "    temp_data = []\n",
    "    point = ee.Geometry.Point(coordinates[i])\n",
    "\n",
    "    processed_dates = set()\n",
    "\n",
    "    # filter\n",
    "    filtered_dataset_ = filtered_dataset.filterBounds(point)\n",
    "\n",
    "    for image in filtered_dataset_.toList(filtered_dataset_.size()).getInfo():\n",
    "        image_date = datetime.utcfromtimestamp(image['properties']['system:time_start'] / 1000.0).strftime('%Y-%m-%d')\n",
    "        print(f\"Processing image for date: {image_date}\")\n",
    "\n",
    "        if image_date in processed_dates:\n",
    "            print(f\"Skipping image for date {image_date} as it's already processed.\")\n",
    "            continue\n",
    "\n",
    "        selected_image = ee.Image(image['id'])\n",
    "        rgb_image = selected_image.select(['B4', 'B3', 'B2'])\n",
    "\n",
    "        url = rgb_image.getThumbURL({'dimensions': 256, 'format': 'png'})\n",
    "\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        img = img.convert(\"RGB\")  \n",
    "\n",
    "        input_shape = model.input_shape[1:3]\n",
    "        img = img.resize(input_shape)\n",
    "        image_array = np.array(img) / 255.0 \n",
    "\n",
    "        print(f\"Probability Date: {image_date}\")\n",
    "        prediction = model.predict(np.expand_dims(image_array, axis=0))\n",
    "            \n",
    "        batch, height, width, channel = prediction.shape\n",
    "        center_height = height // 2\n",
    "        center_width = width // 2\n",
    "        center_values = prediction[:, center_height, center_width, :]\n",
    "        print(center_values)\n",
    "\n",
    "        class_probs = {\n",
    "            \"class1\" : float(center_values[0][0]),\n",
    "            \"class2\" : float(center_values[0][1]),\n",
    "            \"class3\" : float(center_values[0][2]),\n",
    "            \"class4\" : float(center_values[0][3]),\n",
    "            \"class5\" : float(center_values[0][4]),\n",
    "            \"class6\" : float(center_values[0][5]),\n",
    "        }\n",
    "\n",
    "        new_data = {\n",
    "            \"date\" : image_date, \n",
    "            \"lon\" : float(coordinates[i][0]),\n",
    "            \"lat\" : float(coordinates[i][1]),\n",
    "            \"classes\" : class_probs,  \n",
    "        }\n",
    "\n",
    "        processed_dates.add(image_date)\n",
    "\n",
    "        temp_data.append(new_data)\n",
    "\n",
    "    data[i] = temp_data\n",
    "\n",
    "\n",
    "with open('100points_probabilities.json', 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
