{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras import applications, optimizers\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_inception_resnetv2_unet(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \"\"\" Pre-trained InceptionResNetV2 Model \"\"\"\n",
    "    encoder = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = encoder.get_layer(\"input_1\").output           ## (512 x 512)\n",
    "\n",
    "    s2 = encoder.get_layer(\"activation\").output        ## (255 x 255)\n",
    "    s2 = ZeroPadding2D(( (1, 0), (1, 0) ))(s2)         ## (256 x 256)\n",
    "\n",
    "    s3 = encoder.get_layer(\"activation_3\").output      ## (126 x 126)\n",
    "    s3 = ZeroPadding2D((1, 1))(s3)                     ## (128 x 128)\n",
    "\n",
    "    s4 = encoder.get_layer(\"activation_74\").output      ## (61 x 61)\n",
    "    s4 = ZeroPadding2D(( (2, 1),(2, 1) ))(s4)           ## (64 x 64)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = encoder.get_layer(\"activation_161\").output     ## (30 x 30)\n",
    "    b1 = ZeroPadding2D((1, 1))(b1)                      ## (32 x 32)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
    "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
    "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
    "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
    "    \n",
    "    \"\"\" Output \"\"\"\n",
    "    dropout = Dropout(0.3)(d4)\n",
    "    outputs = Conv2D(6, 1, padding=\"same\", activation=\"softmax\")(dropout)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"InceptionResNetV2-UNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n",
    "\n",
    "model = build_inception_resnetv2_unet(input_shape = (512, 512, 3))\n",
    "model.compile(optimizer=Adam(lr = 0.0001), loss='categorical_crossentropy', metrics=[dice_coef, \"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"InceptionResNetV2-UNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open('/media/kursat/TOSHIBA EXT16/projects/satellite/YENI/plots/correct_images/2022-12-30.jpg')\n",
    "image = image.convert(\"RGB\")  \n",
    "\n",
    "input_shape = model.input_shape[1:3]\n",
    "image = image.resize(input_shape)\n",
    "image_array = np.array(image) / 255.0  \n",
    "\n",
    "prediction = model.predict(np.expand_dims(image_array, axis=0))\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_map = np.argmax(prediction, axis=-1)\n",
    "\n",
    "num_classes = model.output_shape[-1]\n",
    "print(num_classes)\n",
    "colors = [np.random.randint(0, 256, 3) for _ in range(num_classes)]\n",
    "segmentation_map_color = np.zeros_like(image_array)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    segmentation_map_color[segmentation_map[0] == i] = colors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(image_array)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(segmentation_map_color[:, :, 0])\n",
    "plt.title('Prediction')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
